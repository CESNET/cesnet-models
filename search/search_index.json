{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"CESNET Models","text":"<p>This is documentation of the CESNET Models project. </p> <p>The goal of this project is to provide neural network architectures for traffic classification and their pre-trained weights. The weights were trained using public datasets available in the CESNET DataZoo package.</p> <p>The newest network architecture is called 30pktTCNET. It processes packet sequences in order to create flow embeddings that are useful across traffic classification tasks. See the getting started page and models reference for more information.</p>"},{"location":"#30pkttcnet","title":"30pktTCNET","text":"<p>An older network architecture, which apart from packet sequences also utilizes flow statistics, is named Multi-modal CESNET v2 (mm-CESNET-v2).</p>"},{"location":"#multi-modal-cesnet-v2","title":"Multi-modal CESNET v2","text":""},{"location":"#papers","title":"Papers","text":"<p>Models from the following papers are included:</p> <ul> <li> <p>Fine-grained TLS services classification with reject option  Jan Luxemburk and Tom\u00e1\u0161 \u010cejka  Computer Networks, 2023</p> </li> <li> <p>Encrypted traffic classification: the QUIC case  Jan Luxemburk and Karel Hynek  2023 7th Network Traffic Measurement and Analysis Conference (TMA)</p> </li> </ul>"},{"location":"getting_started/","title":"Getting started","text":""},{"location":"getting_started/#jupyter-notebooks","title":"Jupyter notebooks","text":"<p>Example Jupyter notebooks are provided at https://github.com/CESNET/cesnet-tcexamples. Start with:</p> <ul> <li>Training of a neural network from scratch with data transformations - example_train_nn.ipynb</li> <li>Evaluate a pre-trained neural network I (TLS) - reproduce_tls.ipynb</li> <li>Evaluate a pre-trained neural network II (QUIC) - reproduce_quic.ipynb</li> <li>Multi-dataset evaluation of the 30pktTCNET_256 model cross_dataset_evaluation.ipynb</li> </ul>"},{"location":"getting_started/#code-snippets","title":"Code snippets","text":"<p><pre><code>from cesnet_models.models import MM_CESNET_V2_Weights, mm_cesnet_v2\n\npretrained_weights = MM_CESNET_V2_Weights.CESNET_QUIC22_Week44\nmodel = mm_cesnet_v2(weights=pretrained_weights, model_dir=\"models/\")\n</code></pre> This code will download pre-trained weights into the specified folder and initialize the mm-CESNET-v2 model. Available pre-trained weights for this model are listed in the MM_CESNET_V2_Weights enum and are named based on the dataset and training time period. When weights are specified, the model is returned in the evaluation mode. To train the model, you should first set it back in the training mode with <code>model.train()</code>.</p>"},{"location":"installation/","title":"Installation","text":"<p>Install the package from pip with:</p> <pre><code>pip install cesnet-models\n</code></pre> <p>or for editable install with:</p> <pre><code>pip install -e git+https://github.com/CESNET/cesnet-models\n</code></pre>"},{"location":"installation/#requirements","title":"Requirements","text":"<p>The <code>cesnet-models</code> package requires Python &gt;=3.10.</p>"},{"location":"installation/#dependencies","title":"Dependencies","text":"Name Version numpy &lt;2.0 scikit-learn torch &gt;=1.10"},{"location":"reference_models/","title":"Available models","text":"<p>All models have the following behavior. When the <code>weights</code> parameter is specified, the pre-trained weights will be downloaded and cached in the <code>model_dir</code> folder. The returned model will be in the evaluation mode.</p>"},{"location":"reference_models/#30pkttcnet_256","title":"30pktTCNET_256","text":"<p>An example of how to feed data into this model is provided in a Jypyter notebook with multi-dataset evaluation. See cross_dataset_evaluation.ipynb.</p>"},{"location":"reference_models/#models.model_30pktTCNET_256","title":"models.model_30pktTCNET_256","text":"<pre><code>model_30pktTCNET_256(weights=None, model_dir=None)\n</code></pre> <p>A single-modal neural network processing sequences of 30 packets and outputting 256-dimensional flow embeddings. For fine-tuning, consider using just the <code>backbone_model</code> attribute of the returned model (an instance of Multimodal_CESNET_Enhanced).</p> <p>Parameters:</p> Name Type Description Default <code>weights</code> <code>Optional[Model_30pktTCNET_256_Weights]</code> <p>If provided, the model will be initialized with these weights.</p> <code>None</code> <code>model_dir</code> <code>Optional[str]</code> <p>If weights are provided, this folder will be used to store the weights.</p> <code>None</code> Source code in <code>cesnet_models\\models.py</code> <pre><code>def model_30pktTCNET_256(weights: Optional[Model_30pktTCNET_256_Weights] = None,\n                         model_dir: Optional[str] = None) -&gt; EmbeddingModel:\n    \"\"\"\n    A single-modal neural network processing sequences of 30 packets and outputting 256-dimensional flow embeddings.\n    For fine-tuning, consider using just the `backbone_model` attribute of the returned model (an instance of Multimodal_CESNET_Enhanced).\n\n    Parameters:\n        weights: If provided, the model will be initialized with these weights.\n        model_dir: If weights are provided, this folder will be used to store the weights.\n    \"\"\"\n    architecture_params = {\n        \"use_mlp_flowstats\": False,\n        \"init_weights\": True,\n        \"cnn_ppi_stem_type\": StemType.EMBED,\n        \"pe_size_embedding\": 20,\n        \"pe_size_include_dir\": False,\n        \"pe_size_init\": PacketSizeInitEnum.PLE,\n        \"pe_size_ple_bin_size\": 100,\n        \"pe_ipt_processing\": ProcessIPT.EMBED,\n        \"pe_ipt_embedding\": 10,\n        \"pe_onehot_dirs\": True,\n        \"conv_normalization\": NormalizationEnum.BATCH_NORM,\n        \"linear_normalization\": NormalizationEnum.BATCH_NORM,\n        \"cnn_ppi_channels\": [192, 256, 384, 448],\n        \"cnn_ppi_strides\": [1, 1, 1, 1],\n        \"cnn_ppi_kernel_sizes\": [7, 7, 5, 3],\n        \"cnn_ppi_use_stdconv\": False,\n        \"cnn_ppi_downsample_avg\": True,\n        \"cnn_ppi_blocks_dropout\": 0.3,\n        \"cnn_ppi_first_bottle_ratio\": 0.25,\n        \"cnn_ppi_global_pool\": GlobalPoolEnum.GEM_3_LEARNABLE,\n        \"cnn_ppi_global_pool_act\": False,\n        \"cnn_ppi_global_pool_dropout\": 0.0,\n        \"use_mlp_shared\": True,\n        \"mlp_shared_size\": 448,\n        \"mlp_shared_dropout\": 0.0\n    }\n    embedding_size = 256\n\n    backbone_model = Multimodal_CESNET_Enhanced(**architecture_params, save_psizes_hist=True)\n    model = EmbeddingModel(backbone_model, embedding_size=embedding_size)\n    if weights is not None:\n        state_dict = weights.get_state_dict(model_dir=model_dir)\n        state_dict.pop(\"arcface_module.W\", None)\n        model.load_state_dict(state_dict)\n        model.eval()\n    return model\n</code></pre>"},{"location":"reference_models/#multi-modal-models","title":"Multi-modal models","text":"<p>When the <code>weights</code> parameter is not specified when using (<code>mm_cesnet_v1</code> and <code>mm_cesnet_v2</code>), the model will be initialized with random weights and the following arguments become required:</p> <ul> <li><code>num_classes</code> - the number of classes, which defines the output size of the last linear layer.</li> <li><code>flowstats_input_size</code> - the number of flow statistics features and, therefore, the input size of the first linear layer processing them.</li> <li><code>ppi_input_channels</code> - the number of channels in PPI sequences. The standard value is three for packet sizes, directions, and inter-arrival times.</li> </ul>"},{"location":"reference_models/#input","title":"Input","text":"<p>Multi-modal models expect input in the format of <code>tuple(batch_ppi, batch_flowstats)</code>. The shapes are:</p> <ul> <li>batch_ppi <code>torch.tensor (B, ppi_input_channels, 30)</code> - batch size of <code>B</code> and  the length of PPI sequences is required to be 30.</li> <li>batch_flowstats <code>torch.tensor (B, flowstats_input_size)</code></li> </ul> <p>All Jupyter notebooks listed on the getting started page show how to feed data into the models.</p>"},{"location":"reference_models/#models.mm_cesnet_v2","title":"models.mm_cesnet_v2","text":"<pre><code>mm_cesnet_v2(\n    weights=None,\n    model_dir=None,\n    num_classes=None,\n    flowstats_input_size=None,\n    ppi_input_channels=None,\n)\n</code></pre> <p>This is a second version of the multimodal CESNET architecture. It was used in the \"Encrypted traffic classification: the QUIC case\" paper.</p> Changes from the first version <ul> <li>Global pooling was added to the CNN part processing PPI sequences, instead of a simple flattening.</li> <li>One more Conv1D layer was added to the CNN part and the number of channels was increased.</li> <li>The size of the MLP processing flow statistics was increased.</li> <li>The size of the MLP processing shared representations was decreased.</li> <li>Some dropout rates were decreased.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>weights</code> <code>Optional[MM_CESNET_V2_Weights]</code> <p>If provided, the model will be initialized with these weights.</p> <code>None</code> <code>model_dir</code> <code>Optional[str]</code> <p>If weights are provided, this folder will be used to store the weights.</p> <code>None</code> <code>num_classes</code> <code>Optional[int]</code> <p>Number of classes.</p> <code>None</code> <code>flowstats_input_size</code> <code>Optional[int]</code> <p>Size of the flow statistics input.</p> <code>None</code> <code>ppi_input_channels</code> <code>Optional[int]</code> <p>Number of channels in the PPI input.</p> <code>None</code> Source code in <code>cesnet_models\\models.py</code> <pre><code>def mm_cesnet_v2(weights: Optional[MM_CESNET_V2_Weights] = None,\n                 model_dir: Optional[str] = None,\n                 num_classes: Optional[int] = None,\n                 flowstats_input_size: Optional[int] = None,\n                 ppi_input_channels: Optional[int] = None,\n                 ) -&gt; Multimodal_CESNET:\n    \"\"\"\n    This is a second version of the multimodal CESNET architecture. It was used in\n    the *\"Encrypted traffic classification: the QUIC case\"* paper.\n\n    Changes from the first version:\n        - Global pooling was added to the CNN part processing PPI sequences, instead of a simple flattening.\n        - One more Conv1D layer was added to the CNN part and the number of channels was increased.\n        - The size of the MLP processing flow statistics was increased.\n        - The size of the MLP processing shared representations was decreased.\n        - Some dropout rates were decreased.\n\n    Parameters:\n        weights: If provided, the model will be initialized with these weights.\n        model_dir: If weights are provided, this folder will be used to store the weights.\n        num_classes: Number of classes.\n        flowstats_input_size: Size of the flow statistics input.\n        ppi_input_channels: Number of channels in the PPI input.\n    \"\"\"\n    v2_model_configuration = {\n        \"conv_normalization\": NormalizationEnum.BATCH_NORM,\n        \"linear_normalization\": NormalizationEnum.BATCH_NORM,\n        \"cnn_ppi_num_blocks\": 3,\n        \"cnn_ppi_channels1\": 200,\n        \"cnn_ppi_channels2\": 300,\n        \"cnn_ppi_channels3\": 300,\n        \"cnn_ppi_use_pooling\": True,\n        \"cnn_ppi_dropout_rate\": 0.1,\n        \"mlp_flowstats_num_hidden\": 2,\n        \"mlp_flowstats_size1\": 225,\n        \"mlp_flowstats_size2\": 225,\n        \"mlp_flowstats_dropout_rate\": 0.1,\n        \"mlp_shared_num_hidden\":  0,\n        \"mlp_shared_size\": 600,\n        \"mlp_shared_dropout_rate\": 0.2,\n    }\n    return _multimodal_cesnet(model_configuration=v2_model_configuration,\n                              weights=weights,\n                              model_dir=model_dir,\n                              num_classes=num_classes,\n                              flowstats_input_size=flowstats_input_size,\n                              ppi_input_channels=ppi_input_channels)\n</code></pre>"},{"location":"reference_models/#models.mm_cesnet_v1","title":"models.mm_cesnet_v1","text":"<pre><code>mm_cesnet_v1(\n    weights=None,\n    model_dir=None,\n    num_classes=None,\n    flowstats_input_size=None,\n    ppi_input_channels=None,\n)\n</code></pre> <p>This model was used in the \"Fine-grained TLS services classification with reject option\" paper.</p> <p>Parameters:</p> Name Type Description Default <code>weights</code> <code>Optional[MM_CESNET_V1_Weights]</code> <p>If provided, the model will be initialized with these weights.</p> <code>None</code> <code>model_dir</code> <code>Optional[str]</code> <p>If weights are provided, this folder will be used to store the weights.</p> <code>None</code> <code>num_classes</code> <code>Optional[int]</code> <p>Number of classes.</p> <code>None</code> <code>flowstats_input_size</code> <code>Optional[int]</code> <p>Size of the flow statistics input.</p> <code>None</code> <code>ppi_input_channels</code> <code>Optional[int]</code> <p>Number of channels in the PPI input.</p> <code>None</code> Source code in <code>cesnet_models\\models.py</code> <pre><code>def mm_cesnet_v1(weights: Optional[MM_CESNET_V1_Weights] = None,\n                 model_dir: Optional[str] = None,\n                 num_classes: Optional[int] = None,\n                 flowstats_input_size: Optional[int] = None,\n                 ppi_input_channels: Optional[int] = None,\n                 ) -&gt; Multimodal_CESNET:\n    \"\"\"\n    This model was used in the *\"Fine-grained TLS services classification with reject option\"* paper.\n\n    Parameters:\n        weights: If provided, the model will be initialized with these weights.\n        model_dir: If weights are provided, this folder will be used to store the weights.\n        num_classes: Number of classes.\n        flowstats_input_size: Size of the flow statistics input.\n        ppi_input_channels: Number of channels in the PPI input.\n    \"\"\"\n    v1_model_configuration = {\n        \"conv_normalization\": NormalizationEnum.BATCH_NORM,\n        \"linear_normalization\": NormalizationEnum.BATCH_NORM,\n        \"cnn_ppi_num_blocks\": 2,\n        \"cnn_ppi_channels1\": 72,\n        \"cnn_ppi_channels2\": 128,\n        \"cnn_ppi_channels3\": 128,\n        \"cnn_ppi_use_pooling\": False,\n        \"cnn_ppi_dropout_rate\": 0.2,\n        \"mlp_flowstats_num_hidden\": 2,\n        \"mlp_flowstats_size1\": 64,\n        \"mlp_flowstats_size2\": 32,\n        \"mlp_flowstats_dropout_rate\": 0.2,\n        \"mlp_shared_num_hidden\": 1,\n        \"mlp_shared_size\": 480,\n        \"mlp_shared_dropout_rate\": 0.2,\n    }\n    return _multimodal_cesnet(model_configuration=v1_model_configuration,\n                              weights=weights,\n                              model_dir=model_dir,\n                              num_classes=num_classes,\n                              flowstats_input_size=flowstats_input_size,\n                              ppi_input_channels=ppi_input_channels)\n</code></pre>"},{"location":"reference_transforms/","title":"Data transformations","text":""},{"location":"reference_transforms/#transforms.ClipAndScalePPI","title":"transforms.ClipAndScalePPI","text":"<p>             Bases: <code>Module</code></p> <p>Transform class for scaling of per-packet information (PPI) sequences. This transform clips packet sizes and inter-packet times and scales them using a specified scaler. This class inherits from <code>nn.Module</code>, and the data transformation is implemented in the <code>forward</code> method.</p> <p>When used with the <code>cesnet-datazoo</code> package, the transform will be fitted during dataset initialization. Otherwise, the <code>psizes_scaler_attrs</code> and <code>ipt_scaler_attrs</code> must be provided. The required entries in <code>psizes_scaler_attrs</code> and <code>ipt_scaler_attrs</code> depend on the scaler used.</p> <ul> <li>For <code>StandardScaler</code>, the required attributes are <code>mean_</code> and <code>scale_</code>.</li> <li>For <code>RobustScaler</code>, the required attributes are <code>center_</code> and <code>scale_</code>.</li> <li>For <code>MinMaxScaler</code>,  the required attributes <code>min_</code> and <code>scale_</code>.</li> </ul> <p>Expected format of input PPI sequences: <code>(batch_size, ppi_length, ppi_channels)</code></p> <p>Info</p> <p>The zero padding in PPI sequences is preserved during scaling, i.e., the padding zeroes are kept in the output.</p> <p>Parameters:</p> Name Type Description Default <code>psizes_scaler_enum</code> <code>ScalerEnum | str</code> <p>What scaler should be used for packet sizes. Options are standard, robust, minmax, and no-scaling.</p> <code>STANDARD</code> <code>ipt_scaler_enum</code> <code>ScalerEnum | str</code> <p>What scaler should be used for inter-packet times. Options are standard, robust, minmax, and no-scaling.</p> <code>STANDARD</code> <code>psizes_min</code> <code>int</code> <p>Clip packet sizes to this minimum value.</p> <code>1</code> <code>psizes_max</code> <code>int</code> <p>Clip packet sizes to this maximum value.</p> <code>1500</code> <code>ipt_min</code> <code>int</code> <p>Clip inter-packet times to this minimum value.</p> <code>0</code> <code>ipt_max</code> <code>int</code> <p>Clip inter-packet times to this maximum value.</p> <code>65000</code> <code>psizes_scaler_attrs</code> <code>Optional[dict[str, list[float]]]</code> <p>To use a pre-fitted packet sizes scaler, provide its attributes here.</p> <code>None</code> <code>ipt_scaler_attrs</code> <code>Optional[dict[str, list[float]]]</code> <p>To use a pre-fitted inter-packet times scaler, provide its attributes here.</p> <code>None</code> Source code in <code>cesnet_models\\transforms.py</code> <pre><code>class ClipAndScalePPI(nn.Module):\n    \"\"\"\n    Transform class for scaling of per-packet information (PPI) sequences. This transform clips packet sizes and inter-packet times and scales them using a specified scaler.\n    This class inherits from `nn.Module`, and the data transformation is implemented in the `forward` method.\n\n    When used with the `cesnet-datazoo` package, the transform will be fitted during dataset initialization. Otherwise, the `psizes_scaler_attrs` and `ipt_scaler_attrs` must be provided.\n    The required entries in `psizes_scaler_attrs` and `ipt_scaler_attrs` depend on the scaler used.\n\n    - For `StandardScaler`, the required attributes are `mean_` and `scale_`.\n    - For `RobustScaler`, the required attributes are `center_` and `scale_`.\n    - For `MinMaxScaler`,  the required attributes `min_` and `scale_`.\n\n    Expected format of input PPI sequences: `(batch_size, ppi_length, ppi_channels)`\n\n    !!! info Padding\n        The zero padding in PPI sequences is preserved during scaling, i.e., the padding zeroes are kept in the output.\n\n    Parameters:\n        psizes_scaler_enum: What scaler should be used for packet sizes. Options are standard, robust, minmax, and no-scaling.\n        ipt_scaler_enum: What scaler should be used for inter-packet times. Options are standard, robust, minmax, and no-scaling.\n        psizes_min: Clip packet sizes to this minimum value.\n        psizes_max: Clip packet sizes to this maximum value.\n        ipt_min: Clip inter-packet times to this minimum value.\n        ipt_max: Clip inter-packet times to this maximum value.\n        psizes_scaler_attrs: To use a pre-fitted packet sizes scaler, provide its attributes here.\n        ipt_scaler_attrs: To use a pre-fitted inter-packet times scaler, provide its attributes here.\n    \"\"\"\n    psizes_scaler: StandardScaler | RobustScaler | MinMaxScaler | None\n    ipt_scaler: StandardScaler | RobustScaler | MinMaxScaler | None\n    psizes_min: int\n    psizes_max: int\n    ipt_min: int\n    ipt_max: int\n\n    def __init__(self,\n                 psizes_scaler_enum: ScalerEnum | str = ScalerEnum.STANDARD,\n                 ipt_scaler_enum: ScalerEnum | str = ScalerEnum.STANDARD,\n                 psizes_min: int = 1,\n                 psizes_max: int = 1500,\n                 ipt_min: int = 0,\n                 ipt_max: int = 65000,\n                 psizes_scaler_attrs: Optional[dict[str, list[float]]] = None,\n                 ipt_scaler_attrs: Optional[dict[str, list[float]]] = None) -&gt; None:\n        super().__init__()\n        if psizes_scaler_enum == ScalerEnum.STANDARD:\n            self.psizes_scaler = StandardScaler()\n        elif psizes_scaler_enum == ScalerEnum.ROBUST:\n            self.psizes_scaler = RobustScaler()\n        elif psizes_scaler_enum == ScalerEnum.MINMAX:\n            self.psizes_scaler = MinMaxScaler()\n        elif psizes_scaler_enum == ScalerEnum.NO_SCALING:\n            self.psizes_scaler = None\n        else:\n            raise ValueError(f\"psizes_scaler_enum must be one of {ScalerEnum.__members__}\")\n        if ipt_scaler_enum == ScalerEnum.STANDARD:\n            self.ipt_scaler = StandardScaler()\n        elif ipt_scaler_enum == ScalerEnum.ROBUST:\n            self.ipt_scaler = RobustScaler()\n        elif ipt_scaler_enum == ScalerEnum.MINMAX:\n            self.ipt_scaler = MinMaxScaler()\n        elif ipt_scaler_enum == ScalerEnum.NO_SCALING:\n            self.ipt_scaler = None\n        else:\n            raise ValueError(f\"ipt_scaler_enum must be one of {ScalerEnum.__members__}\")\n        self.psizes_min = psizes_min\n        self.psizes_max = psizes_max\n        self.ipt_max = ipt_max\n        self.ipt_min = ipt_min\n        self._psizes_scaler_enum = psizes_scaler_enum\n        self._ipt_scaler_enum = ipt_scaler_enum\n\n        if self.psizes_scaler and psizes_scaler_attrs is not None:\n            set_scaler_attrs(scaler=self.psizes_scaler, scaler_attrs=psizes_scaler_attrs)\n        if self.ipt_scaler and ipt_scaler_attrs is not None:\n            set_scaler_attrs(scaler=self.ipt_scaler, scaler_attrs=ipt_scaler_attrs)\n        self.needs_fitting = (self.ipt_scaler and ipt_scaler_attrs is None) or (self.psizes_scaler and psizes_scaler_attrs is None)\n\n    def forward(self, x_ppi: np.ndarray) -&gt; np.ndarray:\n        if self.needs_fitting:\n            raise ValueError(\"Scalers need to be fitted before using the ClipAndScalePPI transform\")\n        x_ppi = x_ppi.transpose(0, 2, 1)\n        orig_shape = x_ppi.shape\n        ppi_channels = x_ppi.shape[-1]\n        x_ppi = x_ppi.reshape(-1, ppi_channels)\n        x_ppi[:, PPI_IPT_POS] = x_ppi[:, PPI_IPT_POS].clip(max=self.ipt_max, min=self.ipt_min)\n        x_ppi[:, PPI_SIZE_POS] = x_ppi[:, PPI_SIZE_POS].clip(max=self.psizes_max, min=self.psizes_min)\n        padding_mask = x_ppi[:, PPI_DIR_POS] == 0 # Mask of zero padding\n        if self.ipt_scaler is not None:\n            x_ppi[:, PPI_IPT_POS] = self.ipt_scaler.transform(x_ppi[:, PPI_IPT_POS].reshape(-1, 1)).reshape(-1) # type: ignore\n        if self.psizes_scaler is not None:\n            x_ppi[:, PPI_SIZE_POS] = self.psizes_scaler.transform(x_ppi[:, PPI_SIZE_POS].reshape(-1, 1)).reshape(-1) # type: ignore\n        x_ppi[padding_mask, PPI_IPT_POS] = 0\n        x_ppi[padding_mask, PPI_SIZE_POS] = 0\n        x_ppi = x_ppi.reshape(orig_shape).transpose(0, 2, 1)\n        return x_ppi\n\n    def to_dict(self) -&gt; dict:\n        d = {\n            \"psizes_scaler_enum\": str(self._psizes_scaler_enum),\n            \"psizes_scaler_attrs\": get_scaler_attrs(self.psizes_scaler) if self.psizes_scaler is not None else None,\n            \"psizes_min\": self.psizes_min,\n            \"psizes_max\": self.psizes_max,\n            \"ipt_scaler_enum\": str(self._ipt_scaler_enum),\n            \"ipt_scaler_attrs\": get_scaler_attrs(self.ipt_scaler) if self.ipt_scaler is not None else None,\n            \"ipt_min\": self.ipt_min,\n            \"ipt_max\": self.ipt_max,\n        }\n        return d\n\n    def __repr__(self) -&gt; str:\n        return f\"{self.__class__.__name__}(psizes_scaler={self._psizes_scaler_enum}, ipt_scaler={self._ipt_scaler_enum}, psizes_min={self.psizes_min}, psizes_max={self.psizes_max}, ipt_min={self.ipt_min}, ipt_max={self.ipt_max})\"\n</code></pre>"},{"location":"reference_transforms/#transforms.ClipAndScaleFlowstats","title":"transforms.ClipAndScaleFlowstats","text":"<p>             Bases: <code>Module</code></p> <p>Transform class for scaling of features describing an entire network flow -- called flow statistics. This transform clips flow statistics to their <code>quantile_clip</code> quantile and scales them using a specified scaler. This class inherits from <code>nn.Module</code>, and the data transformation is implemented in the <code>forward</code> method.</p> <p>When used with the <code>cesnet-datazoo</code> package, the transform will be fitted during dataset initialization. Otherwise, the <code>flowstats_scaler_attrs</code> must be provided. The required entries in <code>flowstats_scaler_attrs</code> depend on the scaler used.</p> <ul> <li>For <code>StandardScaler</code>, the required attributes are <code>mean_</code> and <code>scale_</code>.</li> <li>For <code>RobustScaler</code>, the required attributes are <code>center_</code> and <code>scale_</code>.</li> <li>For <code>MinMaxScaler</code>,  the required attributes <code>min_</code> and <code>scale_</code>.</li> </ul> <p>Expected format of input flow statistics: <code>(batch_size, flowstats_features)</code></p> <p>Parameters:</p> Name Type Description Default <code>flowstats_scaler_enum</code> <code>ScalerEnum | str</code> <p>What scaler should be used for flow statistics. Options are standard, robust, and minmax.</p> <code>ROBUST</code> <code>quantile_clip</code> <code>float</code> <p>Clip flow statistics to this quantile.</p> <code>0.99</code> <code>flowstats_quantiles</code> <code>Optional[list[float]]</code> <p>To use pre-fitted quantiles, provide them here.</p> <code>None</code> <code>flowstats_scaler_attrs</code> <code>Optional[dict[str, list[float]]]</code> <p>To use a pre-fitted scaler, provide its attributes here.</p> <code>None</code> Source code in <code>cesnet_models\\transforms.py</code> <pre><code>class ClipAndScaleFlowstats(nn.Module):\n    \"\"\"\n    Transform class for scaling of features describing an entire network flow -- called flow statistics. This transform clips flow statistics to their `quantile_clip` quantile and scales them using a specified scaler.\n    This class inherits from `nn.Module`, and the data transformation is implemented in the `forward` method.\n\n    When used with the `cesnet-datazoo` package, the transform will be fitted during dataset initialization. Otherwise, the `flowstats_scaler_attrs` must be provided.\n    The required entries in `flowstats_scaler_attrs` depend on the scaler used.\n\n    - For `StandardScaler`, the required attributes are `mean_` and `scale_`.\n    - For `RobustScaler`, the required attributes are `center_` and `scale_`.\n    - For `MinMaxScaler`,  the required attributes `min_` and `scale_`.\n\n    Expected format of input flow statistics: `(batch_size, flowstats_features)`\n\n    Parameters:\n        flowstats_scaler_enum: What scaler should be used for flow statistics. Options are standard, robust, and minmax.\n        quantile_clip: Clip flow statistics to this quantile.\n        flowstats_quantiles:  To use pre-fitted quantiles, provide them here.\n        flowstats_scaler_attrs: To use a pre-fitted scaler, provide its attributes here.\n    \"\"\"\n    flowstats_scaler: StandardScaler | RobustScaler | MinMaxScaler\n    quantile_clip: float\n    flowstats_quantiles: Optional[list[float]]\n\n    def __init__(self,\n                 flowstats_scaler_enum: ScalerEnum | str = ScalerEnum.ROBUST,\n                 quantile_clip: float = 0.99,\n                 flowstats_quantiles: Optional[list[float]] = None,\n                 flowstats_scaler_attrs: Optional[dict[str, list[float]]] = None) -&gt; None:\n        super().__init__()\n        if flowstats_scaler_enum == ScalerEnum.STANDARD:\n            self.flowstats_scaler = StandardScaler()\n        elif flowstats_scaler_enum == ScalerEnum.ROBUST:\n            self.flowstats_scaler = RobustScaler()\n        elif flowstats_scaler_enum == ScalerEnum.MINMAX:\n            self.flowstats_scaler = MinMaxScaler()\n        else:\n            raise ValueError(f\"flowstats_scaler_enum must be one of {ScalerEnum.__members__}\")\n        self.quantile_clip = quantile_clip\n        self._flowstats_scaler_enum = flowstats_scaler_enum\n\n        if flowstats_scaler_attrs is None and flowstats_quantiles is None:\n            self.needs_fitting = True\n        elif flowstats_scaler_attrs is not None and flowstats_quantiles is not None:\n            set_scaler_attrs(scaler=self.flowstats_scaler, scaler_attrs=flowstats_scaler_attrs)\n            self.flowstats_quantiles = flowstats_quantiles\n            self.needs_fitting = False\n        else:\n            raise ValueError(\"flowstats_quantiles and flowstats_scaler_attrs must be both set or both None\")\n\n    def forward(self, x_flowstats: np.ndarray) -&gt; np.ndarray:\n        if self.needs_fitting:\n            raise ValueError(\"Scalers and quantiles need to be fitted before using this transform\")\n        x_flowstats = x_flowstats.clip(min=0, max=self.flowstats_quantiles)\n        x_flowstats = self.flowstats_scaler.transform(x_flowstats) # type: ignore\n        return x_flowstats\n\n    def to_dict(self) -&gt; dict:\n        d = {\n            \"flowstats_scaler_enum\": str(self._flowstats_scaler_enum),\n            \"flowstats_scaler_attrs\": get_scaler_attrs(self.flowstats_scaler),\n            \"flowstats_quantiles\": self.flowstats_quantiles,\n            \"quantile_clip\": self.quantile_clip,\n        }\n        return d\n\n    def __repr__(self) -&gt; str:\n        return f\"{self.__class__.__name__}(flowstats_scaler={self._flowstats_scaler_enum}, quantile_clip={self.quantile_clip})\"\n</code></pre>"},{"location":"reference_transforms/#transforms.NormalizeHistograms","title":"transforms.NormalizeHistograms","text":"<p>             Bases: <code>Module</code></p> <p>Transform class for normalizing packet histograms. This class inherits from <code>nn.Module</code>, and the data transformation is implemented in the <code>forward</code> method.</p> <p>Expected format of input packet histograms: <code>(batch_size, 4 * PHIST_BIN_COUNT)</code>. The input histograms are expected to be in the following order: source packet sizes, destination packet sizes, source inter-packet times, and destination inter-packet times. Each of the four histograms is expected to have <code>PHIST_BIN_COUNT</code> bins, which is 8 in the current implementation.</p> Source code in <code>cesnet_models\\transforms.py</code> <pre><code>class NormalizeHistograms(nn.Module):\n    \"\"\"\n    Transform class for normalizing packet histograms.\n    This class inherits from `nn.Module`, and the data transformation is implemented in the `forward` method.\n\n    Expected format of input packet histograms: `(batch_size, 4 * PHIST_BIN_COUNT)`.\n    The input histograms are expected to be in the following order: source packet sizes, destination packet sizes, source inter-packet times, and destination inter-packet times.\n    Each of the four histograms is expected to have `PHIST_BIN_COUNT` bins, which is 8 in the current implementation.\n    \"\"\"\n    def __init__(self) -&gt; None:\n        super().__init__()\n        self.bins = PHIST_BIN_COUNT\n\n    def forward(self, x_flowstats_phist: np.ndarray) -&gt; np.ndarray:\n        src_sizes_pkt_count = x_flowstats_phist[:, :self.bins].sum(axis=1)[:, np.newaxis]\n        dst_sizes_pkt_count = x_flowstats_phist[:, self.bins:(2*self.bins)].sum(axis=1)[:, np.newaxis]\n        np.divide(x_flowstats_phist[:, :self.bins], src_sizes_pkt_count, out=x_flowstats_phist[:, :self.bins], where=src_sizes_pkt_count != 0)\n        np.divide(x_flowstats_phist[:, self.bins:(2*self.bins)], dst_sizes_pkt_count, out=x_flowstats_phist[:, self.bins:(2*self.bins)], where=dst_sizes_pkt_count != 0)\n        np.divide(x_flowstats_phist[:, (2*self.bins):(3*self.bins)], src_sizes_pkt_count - 1, out=x_flowstats_phist[:, (2*self.bins):(3*self.bins)], where=src_sizes_pkt_count &gt; 1)\n        np.divide(x_flowstats_phist[:, (3*self.bins):(4*self.bins)], dst_sizes_pkt_count - 1, out=x_flowstats_phist[:, (3*self.bins):(4*self.bins)], where=dst_sizes_pkt_count &gt; 1)\n        return x_flowstats_phist\n\n    def __repr__(self) -&gt; str:\n        return f\"{self.__class__.__name__}()\"\n</code></pre>"},{"location":"reference_transforms/#enums-for-configuration","title":"Enums for configuration","text":"<p>The following enums are used for the configuration of transformations.</p>"},{"location":"reference_transforms/#transforms.ScalerEnum","title":"transforms.ScalerEnum","text":"<p>Available scalers for flow statistics, packet sizes, and inter-packet times.</p> STANDARD <code>class-attribute</code> <code>instance-attribute</code> <pre><code>STANDARD = 'standard'\n</code></pre> <p>Standardize features by removing the mean and scaling to unit variance - <code>StandardScaler</code>.</p> ROBUST <code>class-attribute</code> <code>instance-attribute</code> <pre><code>ROBUST = 'robust'\n</code></pre> <p>Robust scaling with the median and the interquartile range - <code>RobustScaler</code>.</p> MINMAX <code>class-attribute</code> <code>instance-attribute</code> <pre><code>MINMAX = 'minmax'\n</code></pre> <p>Scaling to a (0, 1) range - <code>MinMaxScaler</code>.</p>"}]}